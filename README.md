# CAS783
CAS 783 Human Centered Artificial Intelligence 


## Week 2
* **1978**: "Does the chimpanzee have a theory of mind?" – David Premack and Guy Woodruff

## Week 4
* **2013**: "Too much, too little, or just right? Ways Explanations Impact End Users' Mental Models" – Todd Kulesza, et al.
* **2016**: "Why should I trust you? Explaining the Predictions of Any Classifier" – Marco Tulio Ribeiro, et al.
* **2017**: "GRAD CAM: Visual Explanations from Deep Networks via Gradient-Based Localization" – Ramprasaath R. Selvaraju, et al.

## Week 6
* **2018**: "Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification" – Joy Buolamwini, et al.

## Week 2
* **2018**: "Machine theory of mind" – Neil C. Rabinowitz, et al.

## Week 5
* **2019**: "Explanatory Interactive Machine Learning" – Stefano Teso, et al.

## Week 6
* **2019**: "Model cards for model reporting" – Margaret Mitchell, et al.

## Week 7
* **2019**: "A Mixed-Methods Approach to Understanding User Trust after Voice Assistant Failures" – Amanda Baughan, et al.

## Week 3
* **2020**: "Human-Centered Evaluation of a Deep Learning System" – Emma Beede, et al.

## Week 5
* **2020**: "Beyond Accuracy: Behavioral Testing of NLP Models with CheckList" – Marco Tulio Ribeiro, et al.

## Week 3
* **2021**: "Deep learning system for detecting diabetic retinopathy across the disease spectrum" – Ling Dai, et al.

## Week 4
* **2021**: "Manipulating and Measuring Model Interpretability" – Forough Poursabzi-Sangdeh, et al.

## Week 2
* **2022**: "Humanness lies in unpredictability: Role of Theory of Mind on anthropomorphism in human-computer interactions" – Julia Ayache, et al.

## Week 6
* **2022**: "Mitigating the impact of biased ai" – Hammaad Adam, et al.

## Week 5
* **2023**: "Quantus: An Explainable AI Toolkit for Responsible Evaluation of Neural Network Explanations and Beyond" – Anna Hedström, et al.
* **2023**: "Talk to model" – Dylan Slack, et al.

## Week 3
* **2023**: "Physician detection of Clinical harm in machine translation" – Nikita Mehandru, et al.

## Week 7
* **2023**: "Appropriate Reliance on AI Advice: Conceptualization and the Effect of Explanations" – Max Schemmer, et al.
* **2023**: "Explanations Can Reduce Overreliance on AI" – Helena Vasconcelos, et al.
* **2023**: "Will You Accept an Imperfect AI?" – Rafal Kocielnik, et al.

## Week 2
* **2024**: "Testing theory of mind in LLMs" – James W. A. Strachan, et al.

## Week 3
* **2024**: "Adapted LLMs Can Outperform medical experts in Clinical text summarization" – Dave Van Veen, et al.

## Week 9
* **2024**: "Deep Learning Uncertainty in Machine Teaching"
* **2024**: "Jury Learning: Integrating Dissenting Voices into Machine Learning Models"
* **2024**: "Kaleidoscope: Semantically grounded, context-specific ML model evaluation"
